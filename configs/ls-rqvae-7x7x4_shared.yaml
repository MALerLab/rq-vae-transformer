dataset:
  type: Olimpic_grandstaff_128_gray
  transforms:
    type: grandstaff128to112

arch:
  type: rq-vae
  code_hier: 1
  hparams:
    bottleneck_type: rq
    embed_dim: 256 # quant dim
    n_embed: 4096 # codebook_size
    latent_shape: [ 7, 7, 256 ]  # could be inferred: H=W=resolution / (2 ** num_down), D=embed_dim
    code_shape: [ 7, 7, 4 ]  # 7x7x4 -> 112x112px 112/16(compression rate)=7, last 4 means 4 codebooks(k=4)
    shared_codebook: True
    decay: 0.99
    restart_unused_codes: true

    loss_type: mse
    latent_loss_weight: 0.25
  ddconfig:
    double_z: false
    z_channels: 256 # enc out channels
    resolution: 256 # input image size (not the real size but for calculating the conv output size in the enc/dec ConvStacks)
    in_channels: 1 # enc in ch (1 for gray scale)
    out_ch: 1 # dec out ch
    ch: 128 # enc/dec latent ch
    ch_mult: [ 1, 1, 2, 2, 4] # num of conv layers in each block (compression rate f: 2^(len(ch_mult)-1) 2^4=16 -> coverage of a single code is 16*16px
    num_res_blocks: 2
    attn_resolutions: [ 8 ] # resolution at which self-attention occurs (inside conv stack), resolution is derived from the input image size `resolution`. 8 means there's no self-attention with len(ch_mults)=5.
    dropout: 0.00
  checkpointing: true
 

optimizer:
  # Original VQ-GAN: lr = 4.5e-06 * (batch size) -> 5.4e-5 for batch size 12
  type: adam
  init_lr: 4.0e-5
  weight_decay: 0.0
  betas: [0.5, 0.9]
  warmup:
    epoch: 0.5  # 5% of total epochs
    multiplier: 1
    buffer_epoch: 0
    min_lr: 4.0e-5
    mode: fix


experiment:
  batch_size: 320
  epochs: 20000
  save_ckpt_freq: 5
  test_freq: 1

gan:
  disc:
    arch:
      in_channels: 3
      num_layers: 2
      use_actnorm: False
      ndf: 64
      spectral_norm: False

  loss:
    disc_loss: hinge
    gen_loss: vanilla
    disc_weight: 0.75
    perceptual_weight: 1.0
    disc_start: 10000000
